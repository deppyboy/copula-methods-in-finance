{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copula Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions and Basic Properties\n",
    "\n",
    "#### Joint Cumulative Distribution Function \n",
    "\n",
    "Remember that the <b>joint cumulative function</b> of two random variables $X$ and $Y$ is defined as\n",
    "\\begin{align}%\\label{}\n",
    "\\nonumber F_{XY}(x,y)=P(X \\leq x, Y \\leq y).\n",
    "\\end{align}\n",
    "The joint CDF satisfies the following properties:\n",
    "<ol>\n",
    "  <li> $F_X(x)=F_{XY}(x, \\infty)$, for any $x$ (marginal CDF of $X$);</li>\n",
    "\t<li> $F_Y(y)=F_{XY}(\\infty,y)$, for any $y$ (marginal CDF of $Y$);</li>\n",
    "  <li> $F_{XY}(\\infty, \\infty)=1$;</li>\n",
    "  <li> $F_{XY}(-\\infty, y)=F_{XY}(x,-\\infty)=0$;</li>\n",
    "\t<li>\n",
    "   $\\mathbb{P}(x_1 < X \\leq x_2, \\hspace{5pt} y_1  <Y \\leq y_2)=$\n",
    "     $F_{XY}(x_2,y_2)-F_{XY}(x_1,y_2)-F_{XY}(x_2,y_1)+F_{XY}(x_1,y_1)$;\n",
    "\t</li>\n",
    "  <li>if $X$ and $Y$ are independent, then $F_{XY}(x,y)=F_X(x)F_Y(y)$.</li>\n",
    "</ol>\n",
    "</div><br />\n",
    "\n",
    "In particular from property 5, putting $x_2 \\rightarrow +\\infty$ and $y_2 \\rightarrow +\\infty$ we have\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbb{P}(x_1 < X \\leq +\\infty, \\hspace{5pt} y_1  <Y \\leq +\\infty) & =\n",
    "     F_{XY}(+\\infty,+\\infty)-F_{XY}(x_1,+\\infty)-F_{XY}(+\\infty,y_1)+F_{XY}(x_1,y_1) \\\\\n",
    "& = 1 - F_X(x) - F_Y(y) + F_{XY}(x_1,y_1)     \n",
    "\\end{align}\n",
    "\n",
    "If we denote with \n",
    "\n",
    "\\begin{equation}\n",
    "\\bar F_{XY}(x, y ) = \\mathbb{P}[X > x, Y > y]\n",
    "\\end{equation}\n",
    "\n",
    "we finally obtain\n",
    "\n",
    "\\begin{equation}\n",
    "\\bar F_{XY}(x, y ) = 1 - F_X(x) - F_Y(y) + F_{XY}(x, y)\n",
    "\\end{equation}\n",
    "\n",
    "#### Survival Copula\n",
    "\n",
    "-\n",
    "---\n",
    "\n",
    "**Exercise** Assume that $C$ is absolutely continuous. Prove the following identity\n",
    "\n",
    "\\begin{equation}\n",
    "\\iint\\limits_{[0, 1]^2} uv dC(u,v) = \\iint\\limits_{[0, 1]^2}  C(u,v) \\> dudv \n",
    "\\end{equation}\n",
    "\n",
    "**Answer** If $C$ is absolutely continuous then we can write\n",
    "\n",
    "\\begin{equation}\n",
    "dC(u, v) = \\frac{\\partial^2 C(u, v)}{\\partial u \\partial v} du dv\n",
    "\\end{equation}\n",
    "\n",
    "Sostitution of this definition in the left hand member and evaluating the inner integrals by parts give us:\n",
    "\n",
    "\\begin{align}\n",
    "\\int\\limits_0^1\\int\\limits_0^1 uv dC(u,v) & = \\int\\limits_0^1\\int\\limits_0^1 uv \\frac{\\partial^2 C(u, v)}{\\partial u \\partial v} du dv \\\\\n",
    "& = \\int\\limits_0^1 du \\> u \\int\\limits_0^1 dv \\> v \\frac{\\partial^2 C(u, v)}{\\partial u \\partial v} \\\\\n",
    "& = \\int\\limits_0^1 du \\> u \\Biggl( \\Bigl[ v \\frac{\\partial C(u, v)}{\\partial u} \\Bigr]_{v=0}^{v=1} - \\int\\limits_0^1 \\frac{\\partial C(u, v)}{\\partial u} \\Biggr) \\\\\n",
    "& = \\int\\limits_0^1 du \\> u \\Biggl( 1 - \\int\\limits_0^1 \\frac{\\partial C(u, v)}{\\partial u} \\Biggr) \\\\\n",
    "& = \\int\\limits_0^1 du \\> u - \\int\\limits_0^1 \\> dv \\int\\limits_0^1  \\> du \\> u \\frac{\\partial C(u, v)}{\\partial u} \\\\\n",
    "& = \\int\\limits_0^1 du \\> u - \\int\\limits_0^1 \\> dv \\Bigl(\\Bigl[ u C(u, v) \\Bigr]_{u=0}^{u=1} + \\int\\limits_0^1 C(u,v) \\> du \\Bigl) \\\\ \n",
    "& = \\int\\limits_0^1 \\> du \\> u - \\int\\limits_0^1 \\> dv \\> v + \\int\\limits_0^1 \\int\\limits_0^1 C(u,v) \\> dudv = \\int\\limits_0^1 \\int\\limits_0^1 C(u,v) \\> dudv  \n",
    "\\end{align}\n",
    "\n",
    "---\n",
    "\n",
    "**Exercise** Compute the following expression\n",
    "\n",
    "\\begin{equation}\n",
    "\\int\\limits_0^1 \\int\\limits_0^1 C(u,v) \\frac{\\partial C(u,v)}{\\partial u \\partial v} \\>du\\>dv\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "**Answer** Evaluate the inner integral by parts\n",
    "\n",
    "\\begin{align}\n",
    "\\int_{0}^{1}C(u,v)\\frac{\\partial^2}{\\partial u \\partial v}C(u,v)\\,du\\\\=\\left.C(u,v)\\frac{\\partial}{\\partial v}C(u,v)\\right|_{u=0}^{u=1}-\\int_{0}^{1}\\frac{\\partial}{\\partial u}C(u,v)\\frac{\\partial}{\\partial v}C(u,v)\\,du\\\\=v-\\int_{0}^{1}\\frac{\\partial}{\\partial u}C(u,v)\\frac{\\partial}{\\partial v}C(u,v)\\,du\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\int_{0}^{1}\\int_{0}^{1}C(u,v)\\frac{\\partial^2}{\\partial u \\partial v}C(u,v)\\,dudv\\\\=\\frac1{2}-\\int_{0}^{1}\\int_{0}^{1}\\frac{\\partial}{\\partial u}C(u,v)\\frac{\\partial}{\\partial v}C(u,v)\\,dudv.\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependence Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copulas provide a natural way to study and measure dependence between random variables. Copula properties are invariant under strictly increasing transformations of the underlying random variables. Linear correlation (or Pearson’s correlation) is most frequently used in practice as a measure of dependence. However, since linear correlation is not a copula-based measure of dependence, it can often be quite misleading and should not be taken as the canonical dependence measure. Below we recall the basic properties of linear correlation, and then continue with some copula based measures of dependence.\n",
    "\n",
    "### Linear Correlation\n",
    "\n",
    "...\n",
    "\n",
    "### Concordance\n",
    "\n",
    "Concordance concepts, loosely speaking, aim at capturing the fact that the probability of having \"large\" (or \"small\") values of both $X$ and $Y$ is high, while the probability of having \"large\" values of $X$ together with \"small\" values of \"Y\" - or viceversa - is low.\n",
    "\n",
    "Let $(x, y)^T$ and $(\\tilde x, \\tilde y)^T$ be two observations from a vector $(X, Y )^T$ of continuous random variables. Then $(x, y)^T$ and $(\\tilde x, \\tilde y)^T$ are said to be concordant if $(x − \\tilde x)(y − \\tilde y) > 0$, and discordant if $(x − \\tilde x)(y − \\tilde y) < 0$.\n",
    "The following theorem can be found in Nelsen (1999) p. 127. Many of the results in this section are direct consequences of this theorem.\n",
    "\n",
    "<table style=\"border: 1px solid black\">\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "**Theorem**. _Let $(X, Y )^T$ and $(\\tilde X, \\tilde Y )^T$ be independent vectors of continuous random variables with joint distribution functions $H$ and $\\tilde H$, respectively, with common margins $F$ (of $X$ and $\\tilde X$) and $G$ (of $Y$ and $\\tilde Y$). Let $C$ and $\\tilde C$ denote the copulas of $(X, Y )^T$ and $(\\tilde X, \\tilde Y )^T$ respectively,so that $H(x,y)=C(F(x),G(y))$ and $\\tilde H(x,y)= \\tilde C(F(x),G(y))$. Let $Q$ denote the difference between the probability of concordance and discordance of $(X, Y )^T$ and $(\\tilde X, \\tilde Y )^T$ , i.e. let_\n",
    "\n",
    "$$\n",
    "Q=\\mathbb{P}[(X-\\tilde X)(Y-\\tilde Y) > 0]-\\mathbb{P}[(X-\\tilde X)(Y-\\tilde Y) < 0] \n",
    "$$\n",
    "\n",
    "_Then_\n",
    "\n",
    "$$\n",
    "Q=Q(C, \\tilde C) = 4 \\iint\\limits_{[0,1]^2} \\tilde C (u,v) dC(u,v) -1\n",
    "$$\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "_Proof_. Since the random variables are all continuous,\n",
    "$$\n",
    "\\mathbb{P}[(X-\\tilde X)(Y-\\tilde Y) < 0] = 1 -\\mathbb{P}[(X-\\tilde X)(Y-\\tilde Y) > 0] \\Rightarrow Q = 2 \n",
    "\\mathbb{P}[(X-\\tilde X)(Y-\\tilde Y) > 0] - 1\n",
    "$$\n",
    "\n",
    "But\n",
    "\n",
    "$$\n",
    "\\mathbb{P}[(X-\\tilde X)(Y-\\tilde Y) > 0] = \\mathbb{P}[X > \\tilde X, Y > \\tilde Y] + \\mathbb{P}[X <\\tilde X, Y < \\tilde Y]\n",
    "$$\n",
    "\n",
    "and these probabilities can be evaluated by integrating over the distribution of one of the vectors $(X, Y)^T$ or $(\\tilde X, \\tilde Y)^T$. Hence\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbb{P}[X > \\tilde X, Y > \\tilde Y] & = \\mathbb{P}[ \\tilde X < X, \\tilde Y < Y] \\\\\n",
    "& = \\iint\\limits_{\\mathbb{R}^2} \\mathbb{P}[ \\tilde X < x, \\tilde Y < y] \\> dC[F(x), G(y)] \\\\\n",
    "& = \\iint\\limits_{\\mathbb{R}^2} \\tilde C [F(x), G(y)]  \\> dC[F(x), G(y)]\n",
    "\\end{align}\n",
    "\n",
    "Employing the probability-integral transform $u=F(x)$ and $v = G(y)$ then yields\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbb{P}[X > \\tilde X, Y > \\tilde Y] = \\mathbb{P}[ \\tilde X < X, \\tilde Y < Y] \n",
    "= \\iint\\limits_{[0, 1]^2} \\tilde C(u, v)  \\> dC(u, v)\n",
    "\\end{equation}\n",
    "\n",
    "Similarly,\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbb{P}[X < \\tilde X, Y < \\tilde Y] & = \\iint\\limits_{\\mathbb{R}^2} \\mathbb{P}[ \\tilde X > x, \\tilde Y > y] \\> dC[F(x), G(y)] \\\\\n",
    "& = \\iint\\limits_{\\mathbb{R}^2} \\bigl\\{1 - F(x) - G(y) + \\tilde C[F(x), G(y)]    \\bigr\\}  \\> dC[F(x), G(y)] \\\\\n",
    "& = \\iint\\limits_{[0, 1]^2} \\bigl\\{1 - u - v + \\tilde C(u, v)   \\bigr\\}  \\> dC(u, v)\n",
    "\\end{align}\n",
    "\n",
    "But since $C$ is the joint distribution function of a vector $(U, V)^T$ of $U(0, 1)$ random variables, $\\mathbb{E}(U) = \\mathbb{E}(V) = 1/2$, and hence\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbb{P}[X < \\tilde X, Y < \\tilde Y] = 1 - \\frac{1}{2} - \\frac{1}{2} + \\iint\\limits_{[0, 1]^2} \\tilde C(u, v) \\> dC(u, v) =\n",
    "\\iint\\limits_{[0, 1]^2} \\tilde C(u, v) \\> dC(u, v)\n",
    "\\end{equation}\n",
    "\n",
    "Thus\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbb{P}[(X-\\tilde X)(Y-\\tilde Y) > 0] = 2 \\iint\\limits_{[0, 1]^2} \\tilde C(u, v) \\> dC(u, v)\n",
    "\\end{equation}\n",
    "\n",
    "and the conclusion follows\n",
    "\n",
    "\\begin{equation}\n",
    "Q = 2 \\mathbb{P}[(X-\\tilde X)(Y-\\tilde Y) > 0] - 1 = 4 \\iint\\limits_{[0, 1]^2} \\tilde C(u, v) \\> dC(u, v) - 1\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kendall's tau and Spearman's rho\n",
    "___\n",
    "\n",
    "**Definition** Kendall's tau for the random vector $(X, Y)^T$ is defined as\n",
    "\n",
    "\\begin{equation}\n",
    "\\tau (X, Y) =\\mathbb{P}[(X-\\tilde X)(Y-\\tilde Y) > 0]-\\mathbb{P}[(X-\\tilde X)(Y-\\tilde Y) < 0] \n",
    "\\end{equation}\n",
    "\n",
    "where $(\\tilde X, \\tilde Y)^T$ is an independent copy of $(X, Y)^T$.\n",
    "___\n",
    "\n",
    "Hence Kendall's tau for $(X, Y)^T$ is simply the probability of concordance minus the probability of discordance and since the copula of  $(\\tilde X, \\tilde Y)^T$ is the same of $(X, Y)^T$ is also simply equal to $Q(C, C)$:\n",
    "\n",
    "___\n",
    "\n",
    "**Theorem** _Let $(X, Y)^T$ be a vector of continuous random variables with copula $C$. Then Kendall's tau for $(X, Y)^T$ is given by _\n",
    "\n",
    "\\begin{equation}\n",
    "\\tau (X,Y) = Q(C, C) = 4 \\iint\\limits_{[0, 1]^2} C(u, v) \\> dC(u, v) - 1\n",
    "\\end{equation}\n",
    "___\n",
    "\n",
    "Note that the integral above is the expected value of the random variable $C(U, V)$, where $U, V \\sim U(0, 1)$ with joint distribution function $C$, i.e. $\\tau = 4 \\mathbb{E}(C(U,V)) - 1$.\n",
    "\n",
    "___\n",
    "\n",
    "**Definition** Spearman's rho for the random vector  $(X, Y)^T$ is defined as\n",
    "\n",
    "\\begin{equation}\n",
    "\\rho_S (X, Y) =3 (\\mathbb{P}[(X-\\tilde X)(Y-Y^\\prime) > 0]-\\mathbb{P}[(X-\\tilde X)(Y-Y^\\prime ) < 0]) \n",
    "\\end{equation}\n",
    "\n",
    "where $(X, Y)^T$, $(\\tilde X, \\tilde Y)^T$ and $(X^\\prime, Y^\\prime)^T$ are **independent** copies.\n",
    "\n",
    "___\n",
    "\n",
    "**ricordare che siccome i vettori sono indipendenti la seconda copula è la copula prodotto $\\Pi$**\n",
    "\n",
    "\n",
    "**Theorem** Let $(X, Y)^T$ be a vector of continuous random variables with copula $C$. Then Spearman's rho for $(X, Y)^T$ is given by\n",
    "\n",
    "\\begin{align}\n",
    "\\rho_S (X, Y) & = 3Q(C, \\Pi) = 12 \\iint\\limits_{[0, 1]^2} uv \\> dC(u, v) - 3 = 12 \\iint\\limits_{[0, 1]^2} C(u,v) \\>du\\>dv - 3 \\\\\n",
    "& = \\frac{\\mathbb{E}(UV) - 1/4}{1/12} = \\frac{Cov(U, V)}{\\sqrt{Var(U)}\\sqrt{Var(V)}} \\\\\n",
    "& = \\rho[F(X), G(Y)]\n",
    "\\end{align}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
